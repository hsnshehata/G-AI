const OpenAI = require('openai');
const Bot = require('../models/Bot');

// ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ù…Ù† GPT Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø©
const generateAIResponse = async (req, res) => {
  try {
    const { message, botId } = req.body;
    if (!message || !botId) return res.status(400).json({ error: 'Missing message or botId' });

    const bot = await Bot.findById(botId);
    if (!bot) return res.status(404).json({ error: 'Bot not found' });

    const openai = new OpenAI({ apiKey: bot.openaiKey || process.env.API_KEY });

    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [{ role: 'user', content: message }],
    });

    const reply = response.choices[0]?.message?.content || 'Ù…Ø¹Ù†Ø¯ÙŠØ´ Ø±Ø¯ Ø¯Ù„ÙˆÙ‚ØªÙŠ ðŸ§';
    res.json({ reply });
  } catch (err) {
    console.error('GPT error:', err);
    res.status(500).json({ error: 'AI processing failed' });
  }
};

// Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ ØµÙˆØ±Ø© (ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4o)
const analyzeImageAndRespond = async (req, res) => {
  try {
    const { imageUrl, botId } = req.body;
    if (!imageUrl || !botId) return res.status(400).json({ error: 'Missing image or botId' });

    const bot = await Bot.findById(botId);
    if (!bot) return res.status(404).json({ error: 'Bot not found' });

    const openai = new OpenAI({ apiKey: bot.openaiKey || process.env.API_KEY });

    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: 'Ø­Ù„Ù„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ£Ø®Ø¨Ø±Ù†ÙŠ Ø¨Ù…Ø§ ØªØ±Ø§Ù‡Ø§' },
        { role: 'user', content: [{ type: 'image_url', image_url: { url: imageUrl } }] },
      ],
    });

    const reply = response.choices[0]?.message?.content || 'Ù…Ø´ Ø´Ø§ÙŠÙ Ø§Ù„ØµÙˆØ±Ø© ÙƒÙˆÙŠØ³ ðŸ™ˆ';
    res.json({ reply });
  } catch (err) {
    console.error('Image AI error:', err);
    res.status(500).json({ error: 'Image analysis failed' });
  }
};

// ØªØ­ÙˆÙŠÙ„ ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Lemonfox
const transcribeAudioAndRespond = async (req, res) => {
  try {
    const { audioUrl, botId } = req.body;
    if (!audioUrl || !botId) return res.status(400).json({ error: 'Missing audio or botId' });

    const bot = await Bot.findById(botId);
    if (!bot) return res.status(404).json({ error: 'Bot not found' });

    const lemonfoxRes = await fetch('https://api.lemonfox.ai/api/v1/asr/transcribe-url', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': process.env.LEMONFOX_KEY,
      },
      body: JSON.stringify({ url: audioUrl, model: 'general' }),
    });

    const result = await lemonfoxRes.json();
    if (!result.transcription) {
      return res.status(500).json({ error: 'Transcription failed' });
    }

    // Ø¨Ø¹Ø¯ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†ØµØŒ Ù†ÙˆÙ„Ø¯ Ø±Ø¯ Ù…Ù† GPT
    const openai = new OpenAI({ apiKey: bot.openaiKey || process.env.API_KEY });
    const gptResponse = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [{ role: 'user', content: result.transcription }],
    });

    const reply = gptResponse.choices[0]?.message?.content || 'Ù…Ø´ Ø³Ø§Ù…Ø¹Ùƒ ÙƒÙˆÙŠØ³ ðŸ˜…';
    res.json({ reply, transcription: result.transcription });
  } catch (err) {
    console.error('Audio error:', err);
    res.status(500).json({ error: 'Audio processing failed' });
  }
};

module.exports = {
  generateAIResponse,
  analyzeImageAndRespond,
  transcribeAudioAndRespond,
};
